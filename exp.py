"""
Exemples d'utilisation avanc√©e du syst√®me d'orchestration
"""

import requests
import time
import json
from datetime import datetime

# Configuration
ORCHESTRATOR_URL = "http://localhost:5000"

# ============================================
# Exemple 1: Configuration d'une Architecture Web Classique
# ============================================

def setup_web_architecture():
    """
    Cr√©er une architecture web compl√®te avec:
    - 2 serveurs web (Nginx)
    - 1 serveur d'application (Python)
    - 1 base de donn√©es (PostgreSQL)
    """
    print("üèóÔ∏è  Configuration d'une architecture web...")
    
    # Cr√©er les conteneurs
    containers = [
        {
            "name": "nginx_1",
            "image": "nginx:alpine",
            "ports": {"80": "8080"}
        },
        {
            "name": "nginx_2",
            "image": "nginx:alpine",
            "ports": {"80": "8081"}
        },
        {
            "name": "app_server",
            "image": "python:3.9-slim",
            "env": {"APP_ENV": "production"}
        },
        {
            "name": "postgres_db",
            "image": "postgres:14",
            "env": {
                "POSTGRES_PASSWORD": "secret",
                "POSTGRES_DB": "app_db"
            }
        }
    ]
    
    # Cr√©er tous les conteneurs
    for container in containers:
        response = requests.post(
            f"{ORCHESTRATOR_URL}/container/create",
            json=container
        )
        print(f"‚úÖ Conteneur cr√©√©: {container['name']}")
        time.sleep(2)
    
    # D√©finir les relations
    relations = [
        {"from": "nginx_1", "to": "app_server", "type": "depends_on"},
        {"from": "nginx_2", "to": "app_server", "type": "depends_on"},
        {"from": "app_server", "to": "postgres_db", "type": "uses"}
    ]
    
    for relation in relations:
        response = requests.post(
            f"{ORCHESTRATOR_URL}/relation/add",
            json=relation
        )
        print(f"üîó Relation ajout√©e: {relation['from']} -> {relation['to']}")
    
    print("‚úÖ Architecture web configur√©e!")


# ============================================
# Exemple 2: Test de Charge et Monitoring
# ============================================

def load_test_with_monitoring(container_name, duration=60, requests_per_second=10):
    """
    Effectuer un test de charge tout en monitorant les m√©triques
    """
    print(f"üöÄ Test de charge sur {container_name}...")
    print(f"   Dur√©e: {duration}s, RPS: {requests_per_second}")
    
    start_time = time.time()
    request_count = 0
    metrics_history = []
    
    while time.time() - start_time < duration:
        # Envoyer des requ√™tes
        for _ in range(requests_per_second):
            try:
                # Simuler une requ√™te au conteneur
                # (adapter selon votre endpoint)
                request_count += 1
            except:
                pass
        
        # R√©cup√©rer les m√©triques toutes les 5 secondes
        if request_count % (requests_per_second * 5) == 0:
            try:
                response = requests.get(
                    f"{ORCHESTRATOR_URL}/container/{container_name}/metrics"
                )
                metrics = response.json()
                if metrics:
                    latest = metrics[-1]
                    metrics_history.append(latest)
                    
                    print(f"‚è±Ô∏è  {time.time() - start_time:.1f}s - "
                          f"CPU: {latest['cpu_percent']:.1f}%, "
                          f"MEM: {latest['memory_percent']:.1f}%")
            except:
                pass
        
        time.sleep(1 / requests_per_second)
    
    print(f"\n‚úÖ Test termin√©!")
    print(f"   Total requ√™tes: {request_count}")
    
    # Analyser les r√©sultats
    if metrics_history:
        avg_cpu = sum(m['cpu_percent'] for m in metrics_history) / len(metrics_history)
        max_cpu = max(m['cpu_percent'] for m in metrics_history)
        avg_mem = sum(m['memory_percent'] for m in metrics_history) / len(metrics_history)
        
        print(f"\nüìä R√©sultats:")
        print(f"   CPU moyen: {avg_cpu:.2f}%")
        print(f"   CPU max: {max_cpu:.2f}%")
        print(f"   M√©moire moyenne: {avg_mem:.2f}%")


# ============================================
# Exemple 3: Surveillance du Scaling Automatique
# ============================================

def monitor_autoscaling(container_name, check_interval=10, max_duration=300):
    """
    Surveiller le scaling automatique d'un conteneur
    """
    print(f"üëÅÔ∏è  Surveillance du scaling pour {container_name}...")
    
    start_time = time.time()
    scaling_events = []
    previous_replicas = 0
    
    while time.time() - start_time < max_duration:
        try:
            # V√©rifier le nombre de r√©pliques
            response = requests.get(f"{ORCHESTRATOR_URL}/containers/list")
            containers = response.json()['containers']
            
            # Compter les r√©pliques
            replicas = [c for c in containers if c.startswith(container_name)]
            current_replicas = len(replicas)
            
            # D√©tecter un √©v√©nement de scaling
            if current_replicas != previous_replicas:
                event = {
                    'timestamp': datetime.now().isoformat(),
                    'container': container_name,
                    'previous_count': previous_replicas,
                    'new_count': current_replicas,
                    'action': 'scale_up' if current_replicas > previous_replicas else 'scale_down'
                }
                scaling_events.append(event)
                
                print(f"\nüîÑ SCALING D√âTECT√â!")
                print(f"   Conteneur: {container_name}")
                print(f"   {previous_replicas} -> {current_replicas} r√©pliques")
                print(f"   Action: {event['action']}")
                
                previous_replicas = current_replicas
            
            # Afficher l'√©tat actuel
            response = requests.get(
                f"{ORCHESTRATOR_URL}/container/{container_name}/metrics"
            )
            if response.ok:
                metrics = response.json()
                if metrics:
                    latest = metrics[-1]
                    print(f"   CPU: {latest['cpu_percent']:.1f}%, "
                          f"MEM: {latest['memory_percent']:.1f}%, "
                          f"R√©pliques: {current_replicas}")
        
        except Exception as e:
            print(f"‚ùå Erreur: {e}")
        
        time.sleep(check_interval)
    
    # Rapport final
    print(f"\nüìã Rapport de Scaling:")
    print(f"   √âv√©nements d√©tect√©s: {len(scaling_events)}")
    for event in scaling_events:
        print(f"   - {event['timestamp']}: {event['action']} "
              f"({event['previous_count']} -> {event['new_count']})")


# ============================================
# Exemple 4: Simulation de Pic de Charge
# ============================================

def simulate_traffic_spike(container_name, spike_duration=30):
    """
    Simuler un pic de trafic soudain pour tester le scaling
    """
    print(f"‚ö° Simulation d'un pic de charge sur {container_name}...")
    
    # Phase 1: Charge normale (30 req/s)
    print("\nüìä Phase 1: Charge normale (30 req/s)...")
    for i in range(10):
        print(f"   Envoi de requ√™tes... {i+1}/10")
        time.sleep(1)
    
    # Phase 2: PIC de charge (200 req/s)
    print(f"\nüöÄ Phase 2: PIC DE CHARGE (200 req/s pendant {spike_duration}s)!")
    for i in range(spike_duration):
        print(f"   ‚ö° PIC EN COURS... {i+1}/{spike_duration}")
        time.sleep(1)
    
    # Phase 3: Retour √† la normale
    print("\nüìâ Phase 3: Retour √† la normale...")
    for i in range(10):
        print(f"   Charge r√©duite... {i+1}/10")
        time.sleep(1)
    
    # V√©rifier les √©v√©nements de scaling
    try:
        response = requests.get(f"{ORCHESTRATOR_URL}/scaling/history")
        if response.ok:
            history = response.json()
            recent_events = [e for e in history 
                           if e['container_name'] == container_name]
            
            print(f"\nüìä R√©sultats:")
            print(f"   √âv√©nements de scaling: {len(recent_events)}")
            for event in recent_events[-5:]:  # 5 derniers
                print(f"   - {event['event_type']}: "
                      f"CPU pr√©dit {event.get('predicted_cpu', 'N/A')}%")
    except:
        pass


# ============================================
# Exemple 5: Analyse des Performances ML
# ============================================

def analyze_ml_performance():
    """
    Analyser les performances du mod√®le de Machine Learning
    """
    print("ü§ñ Analyse des performances du mod√®le ML...")
    
    try:
        response = requests.get(f"{ORCHESTRATOR_URL}/predictions/accuracy")
        if response.ok:
            data = response.json()
            
            print(f"\nüìä Rapport de Performance ML:")
            print(f"   Nombre de pr√©dictions: {data.get('count', 0)}")
            print(f"   Pr√©cision moyenne: {data.get('accuracy', 0):.2f}%")
            print(f"   Erreur moyenne: {data.get('mean_error', 0):.2f}%")
            
            # Analyser les pr√©dictions r√©centes
            predictions = data.get('predictions', [])
            if predictions:
                print(f"\nüîç Derni√®res pr√©dictions:")
                for pred in predictions[-5:]:
                    print(f"   - Conteneur: {pred['container_name']}")
                    print(f"     Pr√©dit: {pred['predicted_cpu']:.1f}%, "
                          f"R√©el: {pred.get('actual_cpu', 'N/A')}")
                    print(f"     Scaling d√©clench√©: {pred.get('should_scale', False)}")
        else:
            print("‚ùå Impossible de r√©cup√©rer les donn√©es")
    
    except Exception as e:
        print(f"‚ùå Erreur: {e}")


# ============================================
# Exemple 6: Visualisation du Graphe
# ============================================

def visualize_dependencies():
    """
    Obtenir et afficher les d√©pendances entre conteneurs
    """
    print("üåê Visualisation du graphe de d√©pendances...")
    
    try:
        response = requests.get(f"{ORCHESTRATOR_URL}/relations/graph")
        if response.ok:
            graph_data = response.json()
            
            print(f"\nüìä Statistiques du Graphe:")
            print(f"   Conteneurs: {graph_data.get('total_containers', 0)}")
            print(f"   Relations: {graph_data.get('total_relations', 0)}")
            print(f"   Conteneurs isol√©s: {graph_data.get('isolated_containers', 0)}")
            print(f"   Cycles d√©tect√©s: {graph_data.get('cycles', 0)}")
            
            # Afficher les conteneurs critiques
            critical = graph_data.get('most_critical', [])
            if critical:
                print(f"\n‚ö†Ô∏è  Conteneurs critiques (plus de d√©pendants):")
                for container in critical:
                    print(f"   - {container}")
        else:
            print("‚ùå Impossible de r√©cup√©rer le graphe")
    
    except Exception as e:
        print(f"‚ùå Erreur: {e}")


# ============================================
# Menu Principal
# ============================================

def main():
    print("=" * 60)
    print("üê≥ EXEMPLES D'UTILISATION - ORCHESTRATEUR DOCKER")
    print("=" * 60)
    print("\nChoisissez un exemple:")
    print("1. Configuration d'une architecture web")
    print("2. Test de charge avec monitoring")
    print("3. Surveillance du scaling automatique")
    print("4. Simulation de pic de charge")
    print("5. Analyse des performances ML")
    print("6. Visualisation du graphe de d√©pendances")
    print("0. Quitter")
    
    choice = input("\nVotre choix: ")
    
    if choice == "1":
        setup_web_architecture()
    elif choice == "2":
        container = input("Nom du conteneur: ")
        load_test_with_monitoring(container)
    elif choice == "3":
        container = input("Nom du conteneur: ")
        monitor_autoscaling(container)
    elif choice == "4":
        container = input("Nom du conteneur: ")
        simulate_traffic_spike(container)
    elif choice == "5":
        analyze_ml_performance()
    elif choice == "6":
        visualize_dependencies()
    elif choice == "0":
        print("Au revoir!")
        return
    else:
        print("‚ùå Choix invalide")


if __name__ == "__main__":
    main()